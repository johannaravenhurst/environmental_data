---
title: 'Lab 10: ANOVA'
author: "Johanna Ravenhurst"
date: "2022-12-07"
output: 
  html_document:
    theme: cosmo
    toc: true
    toc_float: true
---
I didn't work with other students.

```{r}
#Setup, read in rope data
rm(list = ls())
require(here)
rope   = read.csv(here("data", "rope.csv"))
head(rope)
```
```{r}
rope$rope.type = factor(rope$rope.type)
levels(rope$rope.type)
```
# **Lab Questions**

# **Q1: ANOVA by hand**
**Q1 - Submit the code you used to build your ANOVA by hand. Make sure you use the code template so that you use the same variable names as those which weâ€™ll use for the grading.**

#Number of observations and groups
```{r}
#summary(rope$rope.type)
#summary(rope)
#str(rope)

n_obs = nrow(rope)
n_groups = nlevels(rope$rope.type)

```
#Partitioning Variance:Total

```{r}
#mean rope cut for all observations
mean_cut = mean(rope$p.cut)


#Total sum of squares is the sum of the difference between the observed percent rope cut and the mean rope cut, squared
ss_tot = (sum((rope$p.cut - mean_cut)^2))

#degrees of freedom = n-1, because we only estimated 1 parameter (grand mean)
df_tot = n_obs - 1

```

#Partitioning Variance: Within-Group

```{r}
#first need to calculate the group means
group_means <- aggregate(
  x = rope$p.cut,
  by = list(rope$rope.type), 
  FUN = mean)

agg_resids <- aggregate(
  x = rope$p.cut,
  by = list(rope$rope.type),
  FUN = function(x) (x - mean(x)))
#agg_resids
str(agg_resids)

agg_sum_sq_resids <- aggregate(
  x = rope$p.cut,
  by = list(rope$rope.type),
  FUN = function(x) sum((x - mean(x))^2))
str(agg_sum_sq_resids)

ss_within <- sum(agg_sum_sq_resids$x)

#we calculated 6 group means, so df is n-6
df_within <- n_obs - 6
```

#Partitioning Variance: Among Groups

```{r}
ss_among = ss_tot - ss_within
df_among = n_groups - 1

```

#Normalizing: Mean Squares

```{r}
ms_among  =  ss_among / (n_groups - 1)
ms_within = ss_within / (n_obs - n_groups)
```

#The Test Statistic: F

```{r}
f_ratio = ms_among/ms_within

#Calculate p-value using F distribution
f_pval = 1-pf(f_ratio, (n_groups-1), (n_obs-n_groups))

#p-value is slightly larger than 0.05, so we fail to reject the null hypothesis and say we don't have significant evidence to say that at least one of the means is significantly different from the others. 
```
#ANOVA in R

```{r}
fit_1 = lm(p.cut ~ rope.type, data=rope)
anova_fit_1 = anova(fit_1)
str(anova_fit_1)

anova_fit_1$"Sum Sq"
anova_fit_1$"Df"
anova_fit_1$"F value"
anova_fit_1$"Pr(>F)"
```
#Post-Hoc Testing Walthrough (code not included in output)

```{r include = FALSE}
rope2 = droplevels(
  subset(
    rope,
    rope.type %in% c("PI", "VEL", "XTC"))
)

boxplot(
  p.cut ~ rope.type,
  data = rope2,
  las = 2,
  xlab = "",
  ylab = "Proportion Rope Cut",
  main = "Subset of Rope Data")
mtext("Rope Type", side = 1, line = 3)

#Tuckey HSD test
fit_rope_2 = lm(p.cut ~ rope.type, data=rope2)
rope2_hsd = TukeyHSD(aov(fit_rope_2))
class(rope2_hsd)
round(rope2_hsd$rope.type, digits = 4)
```
#I used self check code and it all looks good

```{r include = FALSE }
#Self check code

# number comparison tolerance
digits_check = 5

# Build the reference model using R functions
fit_1 = lm(p.cut ~ rope.type, data=rope)
anova(fit_1)
anova_fit_1 = anova(fit_1)

# Check degrees of freedom
anova_fit_1$Df == c(df_among, df_within)

# Check sums of squares
round(anova_fit_1$`Sum Sq`, digits = digits_check) == round(c(ss_among, ss_within), digits = digits_check)

# Check mean squares
round(anova_fit_1$`Mean Sq`, digits = digits_check) == round(c(ms_among, ms_within), digits = digits_check)

# Check the F-ratio
round(anova_fit_1$`F value`[1], digits = digits_check) == round(f_ratio, digits = digits_check)

# Check the F test statistic p-value
round(anova_fit_1$`Pr(>F)`[1], digits = digits_check) == round(f_pval, digits = digits_check)
```
# **Q2-4 Model Assumptions: Constant Variance**

**Q2 (1 pt.): Examine the conditional boxplot in the Partitioning Variance: Within-Group section of the walkthrough. Based on the figure, do you think there are equal variances among the groups?**
No, I don't think there are equal variances among the groups based on the conditional boxplot. For example, rope types BLAZE, SB, and VEL are much longer boxes and include a larger variance than the other three groups. 

**Q3 (1 pt.): Conduct a Bartlett test to assess the homogeneity of variances of the percent cut among the rope type groups.**

```{r}
dat_groups = aggregate(
  p.cut ~ rope.type,
  data = rope,
  FUN = c)
#str(dat_groups)

bartlett.test(dat_groups$p.cut, data = rope)
```

**Q4 (2 pts.): Given your graphical assessment (question 2) and the Bartlett test, do you think an ANOVA-type analysis is appropriate on the raw data? Explain why or why not.**
The Bartlett test result was a p-value of 0.00143, which indicates that we have significant evidence to reject the null hypothesis of homogeneity of variance between the rope type groups. My assessment based on the boxplot was also that the variances were likely different for the rope type groups.

This indicates that the assumption of constant variance is not met for these data, and the ANOVA analysis is not appropriate for the raw data. ANOVA is one of the group 1 methods that requires data to meet a set of 4 assumptions, including homogeneity of variance. 

# **Q5-7 Model coefficients and group means**

```{r}
fit_rope_1 = lm(p.cut ~ rope.type, data = rope)
summary(fit_rope_1)
```

**Q5 (1 pt.): Which rope type is the base case?**
BLAZE is the base case

**Q6 (1 pt.): What is the mean percent cut of the base case rope? Show your calculation using value(s) from the model coefficient table.**
Mean percent cut of the base case rope = the coefficient from the Intercept row of the table = 0.367 x 100 = 36.7%


**Q7 (1 pt.): What is the mean percent cut rope type XTC? Show your calculation using value(s) from the model coefficient table.**
Mean percent cut rope type XTC = Intercept + rope.typeXTC = 0.36714 - 0.10164 = 0.2655 x 100 = 26.55%

# **Q8-11 Model Assumptions: Residual Normality**


**Q8 (1 pt.): Use the residuals() function to retrieve the residuals from your model and perform an overall normality test. Report the p-value.**

p-value = 7.238e-07, or <0.0001

```{r}
fit_rope_resid <- residuals(fit_rope_1)
shapiro.test(fit_rope_resid)

```


**Q9 (1 pt.): Do your model residuals meet the normality assumption, and how do you know?**
No, my model residuals do not meet the normality assumption because the Shapiro test resulted in a p-value <0.0001. This indicates that we have significant evidence to reject the null hypothesis that the residuals in our data are normally distributed. 


**Q10 (4 pts.): Perform normality tests on the residuals within each group. How many groups meet the normality assumption? Optional challenge: identify which rope types meet the assumption.**

Groups meet the normality assumption if the Shapiro test results in a p-value greater than 0.05, because then we do not have significant evidence to reject the null hypothesis that the residuals are normally distributed. There are 3 groups that meet the normality assumption. 

The output seems to identify the group output by row. Rows 2, 3, and 4 contain the groups that meet the normality assumption. When viewing the agg_resids dataset, this means rope types BS, PI, and SB meet the normality assumption. 

```{r}
str(agg_resids)

sapply(agg_resids$x, shapiro.test)
levels(agg_resids$"Group.1")

```


**Q11 (1 pt.): Given the results of your tests for residual normality, do you think that a one-way Analysis of Variance is appropriate for this dataset?**

No, a one-way ANOVA is not appropriate for this dataset because the assumption of normality is not met for all of the rope type group residuals. ANOVA is one of the group 1 methods that requires data to meet a set of 4 assumptions, including normally distributed residuals. 

# **Q12-17 Post-Hoc Testing**

```{r}
require(palmerpenguins)
pen_fem = subset(penguins, sex == "female")
```


**Q12 (2 pts.): Create a conditional boxplot of the female penguins: body mass conditioned on species.**

```{r}
 boxplot(
    body_mass_g ~ species, data = pen_fem,
    main = "Body Mass of Female Penguins by Species",
    ylab = "Body Mass(g)",
    xlab = "Species")
```


**Q13 (1 pt.): Based on the boxplot, do you anticipate any problems with residual normality, or homogeneity of variances? Why or why not?**
No, I don't anticipate problems with meeting those assumptions because it looks like these data have similar amounts of variance around the mean. The boxes look like they are all about the same size. It does look like the mean body mass for each species could be significantly different from the other groups.

**Q14 (2 pts.): Conduct a Bartlett test for homogeneity of variances of body mass grouped by species. Hint: use the formula notation. Report the p-value. Is the homogeneity assumption met? Why or why not?**

p-value = 0.9056

Yes, the homogeneity assumption is met because the p-value is greater than 0.05. This means that we do not have significant evidence to reject the null hypothesis that these data have constant variance.

```{r}
bartlett.test(body_mass_g ~ species, data = pen_fem)
```

**Q15 (2 pts.): Fit a linear model of body mass (the response) and species (the predictor) using the female penguin data. Conduct a test for normality of the residuals. Report the p-value. Is the residual normality assumption met? Why or why not?**

p-value = 0.3639

Yes, the normality assumption is met because the p-value is much larger than 0.05. This result from the Shapiro test indicates that we do not have evidence to reject the null hypothesis that the residuals are normally distributed. 

```{r}
fit_bm_species = lm(body_mass_g ~ species, data = pen_fem)
summary(fit_bm_species)

shapiro.test(residuals(fit_bm_species))


```



**Q16 (2 pts.): Conduct a Tukey HSD post-hoc test on your model. Which pair or pairs of species have significantly different body masses?**

The results of the Tukey test indicate that there is a significant difference between the mean body masses of all three pairs of species. All of the p-values of the test for the differences between the pairs are less than 0.05, which indicate significant evidence to reject the null hypothesis of no difference between the mean body mass of the two species included. The three pairs are Chinstrap-Adelie, Gentoo-Adelie, and Gentoo-Chinstrap. 

```{r}
#Tukey HSD test

bm_species_hsd = TukeyHSD(aov(fit_bm_species))
class(bm_species_hsd)

round(bm_species_hsd$species, digits = 4)
```

**Q17 (2 pts.): Describe how your HSD test results match, or do not match, the graphical insight from the conditional boxplot.**

These results match what I would guess from the conditional boxplot. In the boxplot it looks like all of the species' mean body mass values are significantly different, but the Chinstrap and Adelie mean body mass are closer together. In the HSD test results, the Chinstrap-Adelie pair has a higher p-value than the other pairs, indicating that there could be some evidence to support the null hypothesis, but not enough to reach the threshold of 0.05. 
